@article{Larus1993,
abstract = {A program trace lists the addresses of instructions executed and data referenced during a program's execution. Earlier approaches to collecting program traces, including abstract execution and optimal control tracing, are reviewed. Two tracing systems based on these techniques are presented. Results collected when using the later systems on several programs show significant reductions in the cost of collecting traces. Reduction in trace file sizes are also significant.{\textless}{\textless}ETX{\textgreater}{\textgreater}},
author = {Larus, J. R.},
doi = {10.1109/2.211900},
file = {:Users/pwestrich/Google Drive/Papers/1993{\_}Larus{\_}Efficient program tracing.pdf:pdf},
isbn = {0018-9162 VO - 26},
issn = {2233-8268},
journal = {Computer},
keywords = {Control systems,Encapsulation,Protection,Runtime,Shape,abstract execution,instruction sets,instructions,optimal control tracing,program testing,program tracing,trace file sizes},
number = {5},
pages = {52--61},
pmid = {22053303},
title = {{Efficient program tracing}},
volume = {26},
year = {1993}
}
@article{Ball1994,
abstract = {This paper describes algorithms for inserting monitoring code to profile and trace programs. These algorithms greatly reduce the cost of measuring programs with respect to the commonly used technique of placing code in each basic block. Program profiling counts the number of times each basic block in a program executes. Instruction tracing records the sequence of basic blocks traversed in a program execution. The algorithms optimize the placement of counting/tracing code with respect to the expected or measured frequency of each block or edge in a program's control-flow graph. We have implemented the algorithms in a profiling/tracing tool, and they substantially reduce the overhead of profiling and tracing.We also define and study the hierarchy of profiling problems. These problems have two dimensions: what is profiled (i.e., vertices (basic blocks) or edges in a control-flow graph) and where the instrumentation code is placed (in blocks or along edges). We compare the optimal solutions to the profiling problems and describe a new profiling problem: basic-block profiling with edge counters. This problem is important because an optimal solution to any other profiling problem (for a given control-flow graph) is never better than an optimal solution to this problem. Unfortunately, finding an optimal placement of edge counters for vertex profiling appears to be a hard problem in general. However, our work shows that edge profiling with edge counters works well in practice because it is simple and efficient and finds optimal counter placements in most cases. Furthermore, it yields more information than a vertex profile. Tracing also benefits from placing instrumentation code along edges rather than on vertices.},
author = {Ball, Thomas and Larus, James R.},
doi = {10.1145/183432.183527},
file = {:Users/pwestrich/Google Drive/Papers/1994{\_}Ball, Larus{\_}Optimally profiling and tracing programs.pdf:pdf},
isbn = {0897914538},
issn = {01640925},
journal = {Acm Toplas},
number = {4},
pages = {1319--1360},
title = {{Optimally profiling and tracing programs}},
volume = {16},
year = {1994}
}
@article{Xu2010,
abstract = {Automatic bug finding with static analysis requires precise tracking of different memory object values. This paper describes a mem- ory modeling method for static analysis of C programs. It is particularly suitable for precise path-sensitive analyses, e.g., symbolic execution. It can handle almost all kinds of C expressions, including arbitrary levels of pointer dereferences, pointer arithmetic, composite array and struct data types, arbitrary type casts, dynamicmemory allocation, etc. Itmaps aliased lvalue expressions to the identical object without extra alias anal- ysis. The model has been implemented in the Clang static analyzer and enhanced the analyzer a lot by enabling it to have precise value tracking ability},
author = {Xu, Zhongxing and Kremenek, Ted and Zhang, Jian},
doi = {10.1007/978-3-642-16558-0_44},
file = {:Users/pwestrich/Google Drive/Papers/2010{\_}Xu, Kremenek, Zhang{\_}A memory model for static analysis of C programs.pdf:pdf},
isbn = {3-642-16557-5, 978-3-642-16557-3},
journal = {4th International Symposium on Leveraging Applications (ISoLA 2010)},
pages = {535--548},
title = {{A memory model for static analysis of C programs}},
url = {http://dl.acm.org/citation.cfm?id=1939281.1939332{\%}5Cnhttp://rd.springer.com/chapter/10.1007{\%}2F978-3-642-16558-0{\_}44},
year = {2010}
}
@article{Trahay2011,
abstract = {Modern supercomputers with multi-core nodes en- hanced by accelerators, as well as hybrid programming models, introduce more complexity in modern applications. Exploiting efficiently all the resources requires a complex analysis of the performance of applications in order to detect time-consuming or idle sections. This paper presents EZTRACE, a generic trace generation framework that aims at providing a simple way to analyze applications. EZTRACE is based on plugins that allow it to trace different programming models such as MPI, pthread or OpenMP as well as user-defined libraries or application. This framework uses two steps: one to collect the basic information during execution and one post-mortem analysis. This permits tracing the execution of applications with low overhead while allowing to refine the analysis after the execution of the program. We also present a simple script language for EZTRACE that gives the user the capability to easily define the functions to instrument without modifying the source code of the application. The evaluation of EZTRACE shows that the framework offers a convenient way to analyze applications without impacting the execution.},
author = {Trahay, Fran{\c{c}}ois and Rue, Fran{\c{c}}ois and Faverge, Mathieu and Ishikawa, Yutaka and Namyst, Raymond and Dongarra, Jack},
doi = {10.1109/CCGrid.2011.83},
file = {:Users/pwestrich/Google Drive/Papers/2011{\_}Trahay et al.{\_}EZTrace a generic framework for performance analysis.pdf:pdf},
isbn = {978-1-4577-0129-0},
journal = {International Symposium on Cluster, Cloud and Grid Computing (CCGrid)},
pages = {618--619},
title = {{EZTrace: a generic framework for performance analysis}},
year = {2011}
}
@book{Pacheco2011,
abstract = {With the coming of multicore processors and the cloud, parallel computing is most cer-tainly not a niche area off in a corner of the computing world. Parallelism has become central to the efficient use of resources, and this new textbook by Peter Pacheco will go a long way toward introducing students early in their academic careers to both the art and practice of parallel computing. An Introduction to Parallel Programming illustrates fundamental programming principles in the increasingly important area of shared-memory programming using Pthreads and OpenMP and distributed-memory programming using MPI. More important, it empha-sizes good programming practices by indicating potential performance pitfalls. These topics are presented in the context of a variety of disciplines, including computer science, physics, and mathematics. The chapters include numerous programming exercises that range from easy to very challenging. This is an ideal book for students or professionals looking to learn parallel programming skills or to refresh their knowledge.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Pacheco, Peter S.},
booktitle = {Elsevier Inc.},
doi = {10.1007/978-1-4471-2736-9},
eprint = {arXiv:1011.1669v3},
file = {:Users/pwestrich/Google Drive/Papers/2011{\_}Pacheco{\_}Introduction to Parallel Programming.pdf:pdf},
isbn = {9780123814722},
issn = {01928651},
keywords = {and this new textbook,area off in a,by peter pacheco will,central to the efficient,cer-,cloud,corner of the computing,go a,multicore processors and the,parallel computing is most,parallelism has become,praise of an introduction,tainly not a niche,to parallel programming,use of resources,with the coming of,world},
pages = {391},
pmid = {17565499},
title = {{Introduction to Parallel Programming}},
url = {http://aims.me.cycu.edu.tw/courses/101-2/IPMC/lecture{\_}material/Introduction to Parallel Programming - Peter Pacheco (2010).pdf},
year = {2011}
}
@article{Coulomb2012,
author = {Coulomb, Kevin and Degomme, Augustin and Faverge, Mathieu and Coulomb, Kevin and Degomme, Augustin and Faverge, Mathieu},
file = {:Users/pwestrich/Google Drive/Papers/2012{\_}Coulomb et al.{\_}An open source tool chain for performance analysis To cite this version analysis.pdf:pdf},
title = {{An open source tool chain for performance analysis To cite this version : analysis}},
year = {2012}
}
@phdthesis{Stechschulte2012,
abstract = {Parallel programming introduces new types of bugs that are notoriously difficult to find. As a result researchers have put a significant amount of effort into creating tools and techniques to discover parallel bugs. One of these bugs is the violation of the assumption of atomicity— the assumption that a region of code, called a critical section, executes without interruption from an outside operation. In this thesis, we introduce a new heuristic to infer critical sections using the temporal and spatial locality of critical sections and provide empirical results showing that the heuristic can infer critical sections in shared memory programs. Real critical sections in benchmark programs are completely covered by inferred critical sections up to 75{\%} to 80{\%} of the time. A programmer can use the reported critical sections to inform his addition of locks into the program.},
author = {Stechschulte, Lisa Marie},
file = {:Users/pwestrich/Google Drive/Papers/2012{\_}Stechschulte{\_}AUTOMATIC CRITICAL SECTION DISCOVERY USING MEMORY USAGE PATTERNS.pdf:pdf},
pages = {82},
school = {University of Maryland, College Park},
title = {{AUTOMATIC CRITICAL SECTION DISCOVERY USING MEMORY USAGE PATTERNS.}},
year = {2012}
}
@article{Mohror2012,
abstract = {Accurate performance analysis of high end systems requires event-based traces to correctly identify the root cause of a number of the complex performance problems that arise on these highly parallel systems. These high-end architectures contain tens to hundreds of thousands of processors, pushing application scalability challenges to new heights. Unfortunately, the collection of event-based data presents scalability challenges itself: the large volume of collected data increases tool overhead, and results in data files that are difficult to store and analyze. Our solution to these problems is a new measurement technique called trace profiling that collects the information needed to diagnose performance problems that traditionally require traces, but at a greatly reduced data volume. The trace profiling technique reduces the amount of data stored by capitalizing on the repeated behavior of programs, and on the similarity of the behavior and performance of parallel processes in an application run. Trace profiling is a hybrid between profiling and tracing, collecting summary information about the event patterns in an application run. Because the data has already been classified into behavior categories, we can present reduced, partially analyzed performance data to the user, highlighting the performance behaviors that comprised most of the execution time. ?? 2012 Elsevier B.V. All rights reserved.},
author = {Mohror, Kathryn and Karavanic, Karen L.},
doi = {10.1016/j.parco.2011.12.003},
file = {:Users/pwestrich/Google Drive/Papers/2012{\_}Mohror, Karavanic{\_}Trace profiling Scalable event tracing on high-end parallel systems.pdf:pdf},
issn = {01678191},
journal = {Parallel Computing},
keywords = {Event tracing,Parallel performance tools,Performance measurement},
number = {4-5},
pages = {194--225},
publisher = {Elsevier B.V.},
title = {{Trace profiling: Scalable event tracing on high-end parallel systems}},
url = {http://dx.doi.org/10.1016/j.parco.2011.12.003},
volume = {38},
year = {2012}
}
@article{Aulagnon2013,
author = {Aulagnon, Charles and Martin-Guillerez, Damien and Ru{\'{e}}, Fran{\c{c}}ois and Trahay, Fran{\c{c}}ois},
doi = {10.1007/978-3-642-36949-0_45},
file = {:Users/pwestrich/Google Drive/Papers/2013{\_}Aulagnon et al.{\_}Runtime function instrumentation with EZTrace.pdf:pdf},
isbn = {9783642369483},
issn = {03029743},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {395--403},
title = {{Runtime function instrumentation with EZTrace}},
volume = {7640 LNCS},
year = {2013}
}
@article{Karneyenka2013,
author = {Karneyenka, Uladzimir},
file = {:Users/pwestrich/Google Drive/Papers/2013{\_}Karneyenka{\_}Valgrind Helgrind DRD and Intel Thread Checker.pdf:pdf},
title = {{Valgrind Helgrind / DRD and Intel Thread Checker}},
year = {2013}
}
@article{Schnorr2013,
author = {Schnorr, Lucas M and Stein, Oliveira and Chassin, Jacques},
file = {:Users/pwestrich/Google Drive/Papers/2013{\_}Schnorr, Stein, Chassin{\_}Paje trace file format, version 1.2.5.pdf:pdf},
pages = {1--19},
title = {{Paje trace file format, version 1.2.5}},
url = {http://paje.sourceforge.net/download/publication/lang-paje.pdf},
year = {2013}
}
@techreport{Iakymchuk2014,
abstract = {In order to design parallel applications that exploit efficiently modern supercomputers with their complex architec- ture, it is required to apply a variety of programming models and techniques. The development of such applications as well as their tuning to achieve the optimal performance is practically impossible without performance analysis tools. In this paper, we present a scalable binary trace library – Lightweight Trace Library (LiTL). LiTL aims at providing performance analysis tools with a low-overhead event recording service. In order to enhance the scalability and the performance of such tools, we implement various optimization strategies and techniques in LiTL. The experiments on a suite of synthetic and standard computation kernels show that the overhead caused by LiTL in conjunction with EZTrace remains low. Furthermore, LiTL often performs better than the existing event recording libraries, saving up to 88{\%} of the CPU time and up to 68{\%} of the disk space. Finally, LiTL is a generic library that can be used in conjunction with a wide range of performance analysis tools.},
address = {{\'{E}}vry, France},
author = {Iakymchuk, Roman and Trahay, Fran{\c{c}}ois},
file = {:Users/pwestrich/Google Drive/Papers/2014{\_}Iakymchuk, Trahay{\_}LiTL Lightweight Trace Library.pdf:pdf},
institution = {Institut Mines-T{\'{e}}l{\'{e}}com – T{\'{e}}l{\'{e}}com SudParis},
keywords = {Performance analysis,binary trace library,hybrid programming models,multi-,threaded applications},
pages = {9},
title = {{LiTL : Lightweight Trace Library}},
url = {https://hal.archives-ouvertes.fr/hal-00918733},
year = {2014}
}
